---
title: "蝚砌??"
output: html_document
---


##### 2018/07/11

### ?颱遙???嚗蝙?R ggplot2?脰????死???
####  ????撱箄??澈
```{r}
    library(ggplot2)
mtcars
```    

####  ??霈嚗????
```{r}
    ggplot(data = mtcars, aes(x = gear)) +
  geom_bar(fill = "pink", colour = "black")
``` 

####  ??霈嚗?蝥??
```{r}
ggplot(data = morley, aes(x =Speed)) +
  geom_histogram(fill = "pink", colour = "black")
``` 

####  ????嚗?蝥s??蝥?
```{r}
ggplot(data = iris, aes(x = Species, y=Petal.Width)) +
  geom_point()
```

####  ????嚗?vs??蝥?
```{r}
ggplot(iris, aes(x=Petal.Width , y= Sepal.Width)) +
  geom_boxplot()
```

### ?颱遙??????
####  ??雯頝舐?

```{r}
source('pttTestFunction.R')
id = c(1:3)
URL = paste0("https://www.ptt.cc/bbs/Makeup/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction, 
       URL = URL, filename = filename)
```

![EX1](https://i.imgur.com/9fYcfXM.png)

####  ???皜??

```{r}
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
toSpace <- content_transformer(function(x, pattern) {
  return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "??")
docs <- tm_map(docs, toSpace, "???")
docs <- tm_map(docs, toSpace, "??")
docs <- tm_map(docs, toSpace, "???")
docs <- tm_map(docs, toSpace, "???")
docs <- tm_map(docs, toSpace, "?")
docs <- tm_map(docs, toSpace, "??")
docs <- tm_map(docs, toSpace, "雿?")
docs <- tm_map(docs, toSpace, "?靽∠??")
docs <- tm_map(docs, toSpace, "?頦Ｚ腺撖行平???")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
docs <- tm_map(docs, toSpace, "憭?")
docs <- tm_map(docs, toSpace, "撠?")
docs <- tm_map(docs, toSpace, "?隞?")
docs <- tm_map(docs, toSpace, "憭批振")
docs <- tm_map(docs, toSpace, "靘")
docs <- tm_map(docs, toSpace, "銝?")
docs <- tm_map(docs, toSpace, "???")
docs <- tm_map(docs, toSpace, "From")
docs <- tm_map(docs, toSpace, "?")
docs <- tm_map(docs, toSpace, "???")
docs <- tm_map(docs, toSpace, "雿?")
docs <- tm_map(docs, toSpace, "?")
docs <- tm_map(docs, toSpace, "???")
docs <- tm_map(docs, toSpace, "??")
docs <- tm_map(docs, toSpace, "憟?")
docs <- tm_map(docs, toSpace, "璉?")
docs <- tm_map(docs, toSpace, "霈?")
docs <- tm_map(docs, toSpace, "靘?")
docs <- tm_map(docs, toSpace, "???")
docs <- tm_map(docs, toSpace, "???")
docs <- tm_map(docs, toSpace, "隞予")
docs <- tm_map(docs, toSpace, "?見")
docs <- tm_map(docs, toSpace, "???")
docs <- tm_map(docs, toSpace, "????")
docs <- tm_map(docs, toSpace, "蝻粹??")
docs <- tm_map(docs, toSpace, "?暺?")
docs <- tm_map(docs, toSpace, "鈭?")
docs <- tm_map(docs, toSpace, "???")
docs <- tm_map(docs, toSpace, "銝")
docs <- tm_map(docs, toSpace, "???")
docs <- tm_map(docs, toSpace, "蝝?")
docs <- tm_map(docs, toSpace, "銝?")
docs <- tm_map(docs, toSpace, "銝?")
docs <- tm_map(docs, toSpace, "瘝?")
docs <- tm_map(docs, toSpace, "敺?")
docs <- tm_map(docs, toSpace, "撠?")
docs <- tm_map(docs, toSpace, "銋?")
docs <- tm_map(docs, toSpace, "?")
docs <- tm_map(docs, toSpace, "?")
docs <- tm_map(docs, toSpace, "?")
docs <- tm_map(docs, toSpace, "雿?")
docs <- tm_map(docs, toSpace, "閬?")
docs <- tm_map(docs, toSpace, "???")
docs <- tm_map(docs, toSpace, "?")
docs <- tm_map(docs, toSpace, "銵?")
docs <- tm_map(docs, toSpace, "??隞?")
docs <- tm_map(docs, toSpace, "瘥??")
docs <- tm_map(docs, toSpace, "鞎?")
docs <- tm_map(docs, toSpace, "???")
docs <- tm_map(docs, toSpace, "?")
docs <- tm_map(docs, toSpace, "???")
docs <- tm_map(docs, toSpace, "?撖?")
docs <- tm_map(docs, toSpace, "閬箏??")
docs <- tm_map(docs, toSpace, "隤?")
docs <- tm_map(docs, toSpace, "???")
docs <- tm_map(docs, toSpace, "???")
docs <- tm_map(docs, toSpace, "???")
docs <- tm_map(docs, toSpace, "???")
docs <- tm_map(docs, toSpace, "??")
docs <- tm_map(docs, toSpace, "憭?")
docs <- tm_map(docs, toSpace, "?隞暻?")
docs <- tm_map(docs, toSpace, "隞暻?")
docs <- tm_map(docs, toSpace, "?镼?")
docs <- tm_map(docs, toSpace, "??蜓")
docs <- tm_map(docs, toSpace, "銋??")
docs <- tm_map(docs, toSpace, "憒??")
docs <- tm_map(docs, toSpace, "???")
docs <- tm_map(docs, toSpace, "??")
docs <- tm_map(docs, toSpace, "??死")
docs <- tm_map(docs, toSpace, "????")
docs <- tm_map(docs, toSpace, "撠?")
docs <- tm_map(docs, toSpace, "??")
docs <- tm_map(docs, toSpace, "鞎?")
docs <- tm_map(docs, toSpace, "???")
docs <- tm_map(docs, toSpace, "??澈")


docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs
```

####  ?????

```{r}
mixseg = worker()
jieba_tokenizer=function(d){
  unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
```

####  ????
```{r}
wordcloud(freqFrame$Var1,freqFrame$Freq,
          scale=c(5,0.1),min.freq=50,max.words=150,
          random.order=TRUE, random.color=FALSE, 
          rot.per=.1, colors=brewer.pal(8, "Dark2"),
          ordered.colors=FALSE,use.r.layout=FALSE,
          fixed.asp=TRUE)
```

